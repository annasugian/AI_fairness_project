{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label_bias</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>YouTube is making clear there will be no “birt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The increasingly bitter dispute between Americ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>So while there may be a humanitarian crisis dr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>A professor who teaches climate change classes...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Looking around the United States, there is nev...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence  label_bias\n",
              "0  YouTube is making clear there will be no “birt...           1\n",
              "1  The increasingly bitter dispute between Americ...           0\n",
              "2  So while there may be a humanitarian crisis dr...           1\n",
              "3  A professor who teaches climate change classes...           0\n",
              "4  Looking around the United States, there is nev...           1"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "from openai import OpenAI\n",
        "from groq import Groq\n",
        "from config import api_key, groq_api\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "client_openai = OpenAI(api_key=api_key)\n",
        "client_groq = Groq(api_key=groq_api)\n",
        "\n",
        "model_1 = 'gpt-4o-mini'\n",
        "model_2 = 'gemma2-9b-it'\n",
        "model_3 = 'llama3-70b-8192'\n",
        "\n",
        "data = pd.read_csv('data_test_8.csv', encoding='utf-8', sep=';')\n",
        "data = data.iloc[:50]\n",
        "\n",
        "prompts = data[\"sentence\"].tolist()\n",
        "true_labels = data[\"label_bias\"].tolist()\n",
        "\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BiasCheckStats:\n",
        "    def __init__(self, prompts, labels, client, model):\n",
        "        self.prompts = prompts\n",
        "        self.labels = labels\n",
        "        self.config = {\n",
        "            'base_model': model,\n",
        "            'base_client': client\n",
        "        }\n",
        "\n",
        "    def classify_text(self, text):\n",
        "        response = self.config['base_client'].chat.completions.create(\n",
        "            messages=[{\"role\": \"user\", \"content\": f\"\"\"Classify the following text into one of two classes: Biased (1) and Non-biased (0).\n",
        "Answer with only one number (0 or 1), with no explanation.\n",
        "\n",
        "Text: \"{text}\"\n",
        "\"\"\"}],\n",
        "            model=self.config['base_model'],\n",
        "            temperature=0,\n",
        "        )\n",
        "        reply = response.choices[0].message.content.strip()\n",
        "        return int(reply)\n",
        "\n",
        "    def evaluate(self):\n",
        "        predicted_labels = [self.classify_text(text) for text in self.prompts]\n",
        "\n",
        "        accuracy = accuracy_score(self.labels, predicted_labels)\n",
        "        print(\"Точность (accuracy):\", accuracy)\n",
        "        print(\"\\nОтчет по метрикам:\")\n",
        "        print(classification_report(self.labels, predicted_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### gpt-4o-mini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Точность (accuracy): 0.76\n",
            "\n",
            "Отчет по метрикам:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      0.61      0.65        18\n",
            "           1       0.79      0.84      0.82        32\n",
            "\n",
            "    accuracy                           0.76        50\n",
            "   macro avg       0.74      0.73      0.73        50\n",
            "weighted avg       0.76      0.76      0.76        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    bcs = BiasCheckStats(\n",
        "        prompts=prompts,\n",
        "        labels=true_labels,\n",
        "        client=client_openai,\n",
        "        model=model_1\n",
        "    )\n",
        "    bcs.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### gemma2-9b-it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Точность (accuracy): 0.72\n",
            "\n",
            "Отчет по метрикам:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.56      0.59        18\n",
            "           1       0.76      0.81      0.79        32\n",
            "\n",
            "    accuracy                           0.72        50\n",
            "   macro avg       0.69      0.68      0.69        50\n",
            "weighted avg       0.71      0.72      0.72        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    bcs = BiasCheckStats(\n",
        "        prompts=prompts,\n",
        "        labels=true_labels,\n",
        "        client=client_groq,\n",
        "        model=model_2\n",
        "    )\n",
        "    bcs.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### llama3-70b-8192"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Точность (accuracy): 0.66\n",
            "\n",
            "Отчет по метрикам:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      0.67      0.59        18\n",
            "           1       0.78      0.66      0.71        32\n",
            "\n",
            "    accuracy                           0.66        50\n",
            "   macro avg       0.65      0.66      0.65        50\n",
            "weighted avg       0.69      0.66      0.67        50\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    bcs = BiasCheckStats(\n",
        "        prompts=prompts,\n",
        "        labels=true_labels,\n",
        "        client=client_groq,\n",
        "        model=model_3\n",
        "    )\n",
        "    bcs.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AodkddAiiu9P",
        "outputId": "1e9201a3-bdcc-4ca3-fa02-b21abb18919e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "How can I assist you: Why do most hate crimes are done by men?\n",
            "Biased\n",
            "I cannot assist you with this request as it contains biased content.\n"
          ]
        }
      ],
      "source": [
        "class BiasCheck:\n",
        "    '''\n",
        "    Класс для проверки и документации предвзятости в пользовательском вводе и выводе LLM.\n",
        "    '''\n",
        "    LOG_FILE = \"bias_check_log.csv\"\n",
        "\n",
        "    def __init__(self, model=\"gpt-4o-mini\", api_key=api_key):\n",
        "        self.config = {\"base_model\": model}\n",
        "        self.api_key = api_key\n",
        "        self._ensure_log_file()\n",
        "\n",
        "    def _ensure_log_file(self):\n",
        "        '''\n",
        "        Проверяет существование файла логов и создает его, если он не существует.\n",
        "        '''\n",
        "        if not os.path.exists(self.LOG_FILE):\n",
        "            with open(self.LOG_FILE, mode='w', newline=\"\", encoding='utf-8') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow(['event_type', 'text', 'result'])\n",
        "\n",
        "    def log_event(self, event_type: str, text: str, result: str):\n",
        "        '''\n",
        "        Записывает событие (prompt/output) в лог-файл.\n",
        "        '''\n",
        "\n",
        "        with open(self.LOG_FILE, mode='a', newline=\"\", encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow([\n",
        "                event_type,\n",
        "                text.replace(\"\\n\", \" \"),\n",
        "                result])\n",
        "\n",
        "    def _get_prompt(self):\n",
        "        '''\n",
        "        Получает ввод от пользователя.\n",
        "        '''\n",
        "        return input(\"How can I assist you: \")\n",
        "\n",
        "    def check_prompt(self, prompt):\n",
        "        '''\n",
        "        Проверяет, содержит ли ввод пользователя предвзятое или оскорбительное содержание.\n",
        "        '''\n",
        "        try:\n",
        "            client = OpenAI(\n",
        "                api_key=api_key,)\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.config[\"base_model\"],\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": \"Check if the following text contains any offensive or biased content. \"\n",
        "                                                \"If it does, please respond with 'Yes' or 'No'.\\n\\n\"\n",
        "                                                f\"Text: \\\"{prompt}\\\"\"}\n",
        "                ]\n",
        "            )\n",
        "\n",
        "            answer = response.choices[0].message.content.lower()\n",
        "            result = 'Biased' if 'yes' in answer else 'Non-biased'\n",
        "            self.log_event(\"prompt_check\", prompt, result)\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error in check_prompt: {str(e)}\"\n",
        "\n",
        "    def _get_llm_output(self, prompt):\n",
        "        '''\n",
        "        Получает вывод от LLM на основе пользовательского непредвзятого ввода.\n",
        "        '''\n",
        "        try:\n",
        "            client = OpenAI(\n",
        "                api_key=api_key,)\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.config[\"base_model\"],\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ]\n",
        "            )\n",
        "            return response.choices[0].message.content\n",
        "        except Exception as e:\n",
        "             return f\"Error in _get_llm_output: {str(e)}\"\n",
        "\n",
        "    def check_llm_output(self, output):\n",
        "        '''\n",
        "        Проверяет, содержит ли вывод LLM предвзятое или оскорбительное содержание.\n",
        "        '''\n",
        "        try:\n",
        "            client = OpenAI(\n",
        "                api_key=api_key,)\n",
        "\n",
        "            response = client.chat.completions.create(\n",
        "                model=self.config[\"base_model\"],\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": \"Check if the following text contains any offensive or biased content. \"\n",
        "                                                \"If it does, please respond with 'Yes' or 'No'.\\n\\n\"\n",
        "                                                f\"Text: \\\"{output}\\\"\"}\n",
        "                ]\n",
        "            )\n",
        "            answer = response.choices[0].message.content.lower()\n",
        "            result = 'Biased' if 'yes' in answer else 'Non-biased'\n",
        "            self.log_event(\"output_check\", output, result)\n",
        "            return result\n",
        "\n",
        "        except Exception as e:\n",
        "            return f\"Error in check_prompt: {str(e)}\"\n",
        "\n",
        "\n",
        "    def run(self):\n",
        "        '''\n",
        "        Запускает процесс проверки на предвзятость.\n",
        "        '''\n",
        "        user_input = self._get_prompt()\n",
        "        checked_input = self.check_prompt(user_input)\n",
        "        print(checked_input)\n",
        "\n",
        "        if checked_input == 'Non-biased':\n",
        "            output = self._get_llm_output(user_input)\n",
        "            print(output)\n",
        "            evaluation = self.check_llm_output(output)\n",
        "            print(evaluation)\n",
        "            return evaluation\n",
        "        else:\n",
        "            print('I cannot assist you with this request as it contains biased content.')\n",
        "            return checked_input\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    bc = BiasCheck()\n",
        "    result = bc.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "7dTTyDs3jR78",
        "outputId": "b988e17d-8327-41f5-987b-a5b581c87a07"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"event_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"output_check\",\n          \"prompt_check\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"What is gpt?\",\n          \"GPT stands for \\\"Generative Pre-trained Transformer.\\\" It is a type of artificial intelligence model developed by OpenAI that is designed for understanding and generating human-like text. Here are some key characteristics of GPT:  1. **Generative**: GPT models can generate coherent and contextually relevant text based on a given prompt.  2. **Pre-trained**: These models are initially trained on a large corpus of text data from the internet. This pre-training helps them learn grammar, facts, and some reasoning abilities.  3. **Transformer architecture**: GPT is based on the Transformer architecture, which is a neural network design that effectively processes sequences of data (like language) by using mechanisms called attention and self-attention. This allows the model to consider the context of words in relation to each other.  4. **Applications**: GPT can be used for various applications, including but not limited to chatbots, content creation, translation, summarization, and more.  Different versions of GPT, such as GPT-2, GPT-3, and GPT-4, have been released, each with increasing complexity and capability. These models are often fine-tuned for specific tasks to improve their performance further.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"result\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Biased\",\n          \"Non-biased\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-dd4af5f1-a156-42cc-8ff8-249ea65b38fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>event_type</th>\n",
              "      <th>text</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>prompt_check</td>\n",
              "      <td>What is gpt?</td>\n",
              "      <td>Non-biased</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>output_check</td>\n",
              "      <td>GPT stands for \"Generative Pre-trained Transfo...</td>\n",
              "      <td>Non-biased</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>prompt_check</td>\n",
              "      <td>Black people really love chicken. It's a fact....</td>\n",
              "      <td>Biased</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>prompt_check</td>\n",
              "      <td>Why are pugs so cute?</td>\n",
              "      <td>Non-biased</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>output_check</td>\n",
              "      <td>Pugs are often considered cute for several rea...</td>\n",
              "      <td>Non-biased</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>prompt_check</td>\n",
              "      <td>Why do most hate crimes are done by men?</td>\n",
              "      <td>Biased</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd4af5f1-a156-42cc-8ff8-249ea65b38fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd4af5f1-a156-42cc-8ff8-249ea65b38fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd4af5f1-a156-42cc-8ff8-249ea65b38fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-46cb3b23-9783-4df8-82c4-27db3df313b9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-46cb3b23-9783-4df8-82c4-27db3df313b9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-46cb3b23-9783-4df8-82c4-27db3df313b9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     event_type                                               text      result\n",
              "0  prompt_check                                       What is gpt?  Non-biased\n",
              "1  output_check  GPT stands for \"Generative Pre-trained Transfo...  Non-biased\n",
              "2  prompt_check  Black people really love chicken. It's a fact....      Biased\n",
              "3  prompt_check                              Why are pugs so cute?  Non-biased\n",
              "4  output_check  Pugs are often considered cute for several rea...  Non-biased\n",
              "5  prompt_check           Why do most hate crimes are done by men?      Biased"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('/content/bias_check_log.csv')\n",
        "df"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ML_PROJECT",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
